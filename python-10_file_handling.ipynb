{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File I/O\n",
    "\n",
    "Open a file\n",
    "\n",
    "Read/Write a file\n",
    "\n",
    "Close a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a file in writing mode\n",
    "f = open('sample.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have to close the file to see the changes, if not nothing would be writen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After closing we can write anything, we have to open it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello Alice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "f.write(\"Hello Alice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write multiline strings in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('sample1.txt', 'w')\n",
    "f.write(\"Hello World\")\n",
    "f.write(\"\\nHello Alice\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanna make changes in the exiting file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('sample.txt', 'w')\n",
    "f.write(\"Changes made\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we see the above code erased the exiting text, that's the problem with 'w' mode.\n",
    "\n",
    "Intropducing append mode 'a' mode\n",
    "\n",
    "To keep the exiting information while making changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('sample.txt','a')\n",
    "f.write(\"\\nWhere do you live\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write lines\n",
    "\n",
    "If we have a list of lines, we can use writelines to insert all the lines to the file from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['Hello Alice\\n','Where are you from?\\n','How do you like it here?']\n",
    "f = open('sample.txt','w')\n",
    "f.writelines(l)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from files\n",
    "\n",
    "In this case we will open the file in 'r' mode and read() function and it's gonna return a string that we see in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Alice\\nWhere are you from?\\nHow do you like it here?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('sample.txt','r')\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce usage of ram we can close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alice\n",
      "Where are you from?\n",
      "How do you like it here?\n"
     ]
    }
   ],
   "source": [
    "f = open('sample.txt','r')\n",
    "s = f.read()\n",
    "print(s)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control the reading: for example, for a very large file if we wanna read just few characters.\n",
    "\n",
    "Character wise.\n",
    "\n",
    "10 represent the number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alic\n"
     ]
    }
   ],
   "source": [
    "f = open('sample.txt','r')\n",
    "s = f.read(10)\n",
    "print(s)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control the reading: for example, for a very large file if we wanna read just few lines.\n",
    "\n",
    "Line wise.\n",
    "\n",
    "We need to call readline()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('sample.txt','r')\n",
    "s = f.readline()\n",
    "print(s)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alice\n",
      "\n",
      "Where are you from?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('sample.txt','r')\n",
    "s1 = f.readline()\n",
    "s2 = f.readline()\n",
    "print(s1)\n",
    "print(s2)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As readline() automatically print a new line that's why we see those extra new line, we can solve this by using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alice\n",
      "Where are you from?\n"
     ]
    }
   ],
   "source": [
    "f = open('sample.txt', 'r')\n",
    "s1 = f.readline()\n",
    "s2 = f.readline()\n",
    "print(s1,end='')\n",
    "print(s2,end='')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alice\n",
      "Where are you from?\n",
      "How do you like it here?"
     ]
    }
   ],
   "source": [
    "f = open('sample.txt', 'r')\n",
    "s = f.readline()\n",
    "while s != '':\n",
    "    print(s, end='')\n",
    "    s = f.readline()  # Read the next line\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using context manager(With)\n",
    "\n",
    "It's a good idea to close a file after usage as it will free up the resources.\n",
    "\n",
    "If we don't close it, garbage collector would close it.\n",
    "\n",
    "'with' keyword closes the file as soon as the usage is over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample1.txt','w') as f:\n",
    "    f.write('Hey! bob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly as with keyword already close the file, the code at bottom is goona give us an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "f.write(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading with 'with' keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! bob\n"
     ]
    }
   ],
   "source": [
    "with open('sample1.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read first 10 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alic\n"
     ]
    }
   ],
   "source": [
    "with open('sample.txt', 'r') as f:\n",
    "    print(f.read(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alic\n",
      "e\n",
      "Where ar\n"
     ]
    }
   ],
   "source": [
    "with open('sample.txt', 'r') as f:\n",
    "    print(f.read(10))\n",
    "    print(f.read(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique usually used to load very big files in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Large_List = ['Hello World' for i in range(1000)]\n",
    "with open('Large.txt','w') as f:\n",
    "    f.writelines(Large_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the large file into chunks, it won't load the whole file rather than in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks Hello Worl Next chunks dHello Wor Next chunks ldHello Wo Next chunks rldHello W Next chunks orldHello  Next chunks WorldHello Next chunks  WorldHell Next chunks o WorldHel Next chunks lo WorldHe Next chunks llo WorldH Next chunks ello World Next chunks "
     ]
    }
   ],
   "source": [
    "with open('Large.txt','r') as f:\n",
    "    chunk_size = 10\n",
    "    s = f.read(chunk_size)\n",
    "    while s!='':\n",
    "        print(s,end=' Next chunks ')\n",
    "        s = f.read(chunk_size)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seek and Tell function\n",
    "\n",
    "We use tell() to get the current position and print it.\n",
    "\n",
    "We use seek() to move to a new position of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a text file\n",
    "with open('story.txt','w') as f:\n",
    "    f.write(\"\"\"In a cozy forest glade,\n",
    "Two rabbits played hopscotch gleefully.\n",
    "Sunset painted the sky,\n",
    "Nature whispered secrets softly.\n",
    "Peace reigned in twilight's embrace.\"\"\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tell() method:\n",
    "\n",
    "Access modes govern the type of operations possible in the opened file. It refers to how the file will be used once itâ€™s opened. These modes also define the location of the File Handle in the file. File handle is like a cursor, which defines from where the data has to be read or written in the file. Sometimes it becomes important for us to know the position of the File Handle. tell() method can be used to get the position of File Handle. tell() method returns current position of file object. This method takes no parameters and returns an integer value. Initially file pointer points to the beginning of the file(if not opened in append mode). So, the initial value of tell() is zero.\n",
    "\n",
    "syntax : \n",
    " \n",
    "\n",
    "file_object.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a cozy \n",
      "10\n"
     ]
    }
   ],
   "source": [
    "with open('story.txt','r') as f:\n",
    "    print(f.read(10))\n",
    "    print(f.tell())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seek() method\n",
    "\n",
    "In Python, seek() function is used to change the position of the File Handle to a given specific position. File handle is like a cursor, which defines from where the data has to be read or written in the file.\n",
    "\n",
    "Syntax: f.seek(offset, from_what), where f is file pointer\n",
    "\n",
    "Parameters: \n",
    "\n",
    "Offset: Number of positions to move forward \n",
    "\n",
    "from_what: It defines point of reference.\n",
    "\n",
    "Returns: Return the new absolute position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a cozy \n",
      "10\n",
      "de,\n",
      "Two ra\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "with open('story.txt','r') as f:\n",
    "    print(f.read(10))\n",
    "    print(f.tell())\n",
    "    f.seek(20)\n",
    "    print(f.read(10))\n",
    "    print(f.tell())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using of seek during writing; using seek we can replace because running write function again will just add characters in this case it's gonna added from the begining. so, it's kind of a over writing because the old characters are gonna replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.txt','w') as f:\n",
    "    f.write(\"Hello Alice\")\n",
    "    f.seek(0)\n",
    "    f.write(\"Deleted\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem working with binary file\n",
    "\n",
    "can't work with binary files like images\n",
    "\n",
    "Not good for other data types like int/float/list/tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "with open('sample.jpeg','r') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the code above can't read an Image file because it's an binary file, this code is only applicable for texts or unicode characters.\n",
    "\n",
    "To solve this we goona make a copy of the image.\n",
    "\n",
    "First, we gonna open the image in 'rb' mode that is read binary mode, use nested with loop to write whatever we read, 'wb' stands foe write binary, and finaly we are writing what we read. This code will create a copy of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.jpeg','rb')as f:\n",
    "    with open('sample_copy.jpeg','wb') as f2:\n",
    "        f2.write(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with other data types like integer, the code crash because it has to be a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not int"
     ]
    }
   ],
   "source": [
    "with open(\"sample.txt\",'w') as f:\n",
    "    f.write(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.txt\",'w') as f:\n",
    "    f.write('4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we try to read the file it's gonna read as a string, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "with open(\"sample.txt\",'r') as f:\n",
    "    f.read() + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only do type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample.txt\",'r') as f:\n",
    "    print(int(f.read()) + 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dictionary data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlice\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m30\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLA\u001b[39m\u001b[38;5;124m'\u001b[39m }\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not dict"
     ]
    }
   ],
   "source": [
    "d = {'Name':'Alice','age':30,'from':'LA' }\n",
    "with open(\"sample.txt\",'w') as f:\n",
    "    f.write(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve this by type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Name':'Alice','age':30,'from':'LA' }\n",
    "with open(\"sample.txt\",'w') as f:\n",
    "    f.write(str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Alice', 'age': 30, 'from': 'LA'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample.txt\",'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even we can read the file it's not the dictionary any more, it become a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample.txt\",'r') as f:\n",
    "    print(type(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now if we try to convert it to a string, we can't because it's a string, so we can't perform any dictonary operations this is the limitations of this code.\n",
    "\n",
    "To overcome this problem we can do next step of codes, serialization and Deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "with open(\"sample.txt\",'r') as f:\n",
    "    print(dict(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization and Deserialization\n",
    "\n",
    ". Serialization - process of converting python data types to JSON format\n",
    "\n",
    ". Deserialization - process of converting JSON to python data types\n",
    "\n",
    "# Serialization\n",
    "Using json module\n",
    "\n",
    "We are gonna convert a list into jason file, we need to import jason, then use json.dump instead of f.write()\n",
    "\n",
    "The json.dump() function\n",
    "\n",
    "The json.dump() function in Python allows you to store JSON data directly into a file. This function takes two parameters: the data to be serialized and the file object where the data will be written.\n",
    "\n",
    "Follow this link to know more: https://www.freecodecamp.org/news/how-to-use-the-json-module-in-python/#:~:text=dump()%20function-,The%20json.,the%20data%20will%20be%20written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "l = [1,2,3,4,5]\n",
    "with open('sample.json','w') as f:\n",
    "    json.dump(l,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d = {'Name':'Alice','age':30,'from':'LA' }\n",
    "with open(\"sample.json\",'w') as f:\n",
    "    json.dump(d,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the json file visually apealing, we can do indentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d = {'Name':'Alice','age':30,'from':'LA' }\n",
    "with open(\"sample.json\",'w') as f:\n",
    "    json.dump(d,f,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deserialization\n",
    "\n",
    "For the Deserialization we can just reverse this process by reading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Alice', 'age': 30, 'from': 'LA'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"sample.json\",'r') as f:\n",
    "    #json.load(f)\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we check the data type, we are gonna see it's not a string like but the same dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"sample.json\",'r') as f:\n",
    "    #json.load(f)\n",
    "    print(type(json.load(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialization and Deserialization with tuples, Unfortunately we can't store tuples in json because json doesn't support tuples file format so convert to it's closest data type that is list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "t = (1,2,3,4,5)\n",
    "with open(\"sample.json\",'w') as f:\n",
    "    json.dump(t,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialization and Deserialization with nested dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d = {'Name':'Alice','age':30,'Hobies':{'Biking':'sometimes','swiming':'everyday'}}\n",
    "with open(\"sample.json\",'w') as f:\n",
    "    json.dump(d,f,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialization and Deserialization with custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a custom object\n",
    "class Person:\n",
    "    def __init__(self,name,age,place):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.place = place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = Person('Alice',30,'LA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to dump this custom object in a json, this code won't work because we can store regular python data types in a json but not really a custon object like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Person is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperson\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Person is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('sample.json','w') as f:\n",
    "    json.dump(person,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell python how are we exctly trying to store this object in the json, so we will create a function that's instruct python how it supposed to dump the object in json.\n",
    "\n",
    "isinstance() is a built-in Python function that is used to check if an object is an instance of a specified class or any of its subclasses. It returns True if the object is an instance of the class or subclass, and False otherwise.\n",
    "\n",
    "The syntax of the isinstance() function is as follows:\n",
    "\n",
    "isinstance(object, classinfo)\n",
    "\n",
    "This process will srote the object in string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dump_object(person):\n",
    "    if isinstance(person,Person):\n",
    "        return \"{} is {} years old and she is from {}\".format(person.name,person.age,person.place)\n",
    "\n",
    "with open('sample.json','w') as f:\n",
    "    json.dump(person,f,default=dump_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the object in dictionary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dump_object(person):\n",
    "    if isinstance(person,Person):\n",
    "        return {'person':person.name,'age':person.age,'place':person.place}\n",
    "\n",
    "with open('sample.json','w') as f:\n",
    "    json.dump(person,f,default=dump_object,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deserialize this we can do something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': 'Alice', 'age': 30, 'place': 'LA'}\n"
     ]
    }
   ],
   "source": [
    "with open('sample.json','r') as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we try to find out the type of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open('sample.json','r') as f:\n",
    "    print(type(json.load(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanna deserialze as an object so we can perform all the task that we do with an object. that's called,\n",
    "\n",
    "# Pickling\n",
    "\n",
    "Pickling is the process of serializing Python objects into a binary format. This binary representation can then be stored in a file or transferred over a network, allowing objects to be saved persistently or transmitted between different Python programs or systems. The serialized data can later be deserialized (unpickled) to reconstruct the original Python objects.\n",
    "\n",
    "Python provides a standard library module called pickle for pickling and unpickling objects. The pickle module allows you to serialize and deserialize objects of almost any type, including built-in types, user-defined classes, and instances.\n",
    "\n",
    "Here's a basic example of how to use pickle for serialization and deserialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 30, 'city': 'New York'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Data to be pickled (serialized)\n",
    "data = {'name': 'Alice', 'age': 30, 'city': 'New York'}\n",
    "\n",
    "# Pickle the data and write it to a file\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# Read the pickled data from the file and unpickle it\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    unpickled_data = pickle.load(f)\n",
    "\n",
    "# Print the unpickled data\n",
    "print(unpickled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a custom object\n",
    "class Person:\n",
    "    def __init__(self,name,age,place):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.place = place\n",
    "\n",
    "    def show_info(self):\n",
    "        print(\"Hello! this is\",self.name,\"I am\",self.age,\"years old and I'm from\",self.place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = Person('Alice',30,'LA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling, converting the object into a binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sample.pkl','wb') as f:\n",
    "    pickle.dump(person,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpickling it, reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Person object at 0x10c81ae10>\n",
      "<class '__main__.Person'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('sample.pkl','rb') as f:\n",
    "    p = pickle.load(f)\n",
    "    print(p)\n",
    "    print(type(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can send this file anywhere, still we can read the file and use as an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! this is Alice I am 30 years old and I'm from LA\n"
     ]
    }
   ],
   "source": [
    "p.show_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
